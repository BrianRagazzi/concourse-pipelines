# Pipeline resource configuration
# opsman_major_minor_version: ^2\.0\..*$   # PCF Ops Manager minor version to track
opsman_major_minor_version: 2\.[0-9\]+\.[0-9]+$
# ert_major_minor_version: ^2\.0\..*$      # PCF Elastic Runtime minor version to track
ert_major_minor_version: 2\.[0-9\]+\.[0-9]+$
nsxt_major_minor_version: ^2\.1\.0.*$   
# scs_major_minor_version: ^1\.5\..*$
# mysql_major_minor_version: ^1\.10\..*$
# rabbitmq_major_minor_version: ^1\.11\..*$

# Whether to allow SSH access to application instances
allow_app_ssh_access: true

## Authentication type needed. SAML is not presently supported.
authentication_mode: internal # (internal|ldap) If ldap, specify ldap configuration below.
first_name_attribute:
group_search_base:
group_search_filter:
last_name_attribute:
ldap_pwd:
ldap_url:
ldap_user:
mail_attribute_name:
search_base:
search_filter:

# AZ configuration for Ops Director
az_1_name: AZ1                    # Logical name of availability zone. No spaces or special characters.
az_1_cluster_name: AZ1            # Name of cluster in vCenter for AZ1
az_1_rp_name: PCF2                 # Resource pool name in vCenter for AZ1
az_2_name: AZ2                    # Logical name of availability zone. No spaces or special characters.
az_2_cluster_name: AZ2            # Name of cluster in vCenter for AZ2
az_2_rp_name: PCF2                 # Resource pool name in vCenter for AZ2
az_3_name: AZ3                    # Logical name of availability zone. No spaces or special characters.
az_3_cluster_name: AZ3            # Name of cluster in vCenter for AZ3
az_3_rp_name: PCF2                 # Resource pool name in vCenter for AZ3


# vSphere datastore folder (such as pcf_disk) where attached disk images will be created
bosh_disk_path: "pcf_disk"

# vSphere datacenter folder (such as pcf_templates) where templates will be placed
bosh_template_folder: "PCF2/Templates"

# vSphere datacenter folder (such as pcf_vms) where VMs will be placed
bosh_vm_folder: "PCF2/VMs"

# Ciphers
# An ordered, colon-delimited list of Golang supported TLS cipher suites in OpenSSL format.
# Operators should verify that these are supported by any clients or downstream components that will initiate TLS handshakes with the Router/HAProxy.
# The recommended settings are filled in below, change as necessary.
haproxy_tls_ciphers: "DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384"
router_tls_ciphers: "ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384"

# Company Name for Apps Manager
company_name: LAB13

# If set to a non-empty string, bypass DNS when uploading stemcells to Ops Manager
company_proxy_domain:

# c2c networking network cidr
container_networking_nw_cidr: 10.255.0.0/16

# For credhub integration, Set the number of credhub instances in resource config to 2
# Primary Encryption Name MUST match one of the encryption key names provided
# Encryption keys 2 and 3 are optional
# Note: The secret key needs to be 20 characters or more.
credhub_password: password123password123password123 # Needs to be min 20 characters
credhub_primary_encryption_name: dummy encryption key 1
credhub_encryption_key_name1: dummy encryption key 1
credhub_encryption_key_secret1: mysupersecretcredhubencryptionkey
credhub_encryption_key_name2: # Optional Name 2
credhub_encryption_key_secret2: # Optional Secret 2
credhub_encryption_key_name3: # Optional Name 3
credhub_encryption_key_secret3: # Optional Secret 2
default_quota_max_number_services: 1000
default_quota_memory_limit_mb: 10240

# PAS 2.1 has GrootFS (garden rootFS) option for app container image
enable_grootfs: true # can be true or false


# Enable external or silk as CNI plugin
container_networking_interface_plugin: external # Default to use "silk"

# Following entry should be updated to include the subnet for the PAS vms
# Cloud Controller wont be able to reach and talk back to the blobstore if the subnet is not correctly included
blobstore_internal_access_subnet: 'allow 10.0.0.0/8;,allow 192.13.0.0/16;,allow 192.168.0.0/16;' # EDIT and make sure the subnet for the PAS is added here

#Director Configuration
ssl_verification_enabled: false
metrics_ip:
opentsdb_ip:
post_deploy_enabled: true
bosh_recreate_on_next_deploy: false
retry_bosh_deploys: false
keep_unreachable_vms: false
director_worker_count: 5
pager_duty_enabled: false
pager_duty_service_key:
pager_duty_http_proxy:
hm_email_enabled: false
smtp_host: mail.lab13.lab.local.domain
smtp_domain:
from_address:
recipients_address:
smtp_password:
smtp_tls_enabled: false
blobstore_type: local #local or s3
s3_bucket_name: pcf2
s3_access_key: MYACCESSKEY
s3_secret_key: MYSECRETKEY
s3_signature_version:
database_type: internal #internal or external
external_mysql_db_host:
external_mysql_db_port:
external_mysql_db_user:
external_mysql_db_password:
external_mysql_db_database:
syslog_enabled: true
syslog_address: syslog.lab13.lab.local.domain
syslog_transport_protocol: udp
syslog_tls_enabled: false
syslog_permitted_peer:
syslog_ssl_ca_certificate:
generate_vm_passwords: true
## Syslog endpoint configuration goes here
# Optional. If syslog_host is specified, syslog_port, syslog_protocol,
# syslog_drain_buffer_size, and enable_security_event_logging must be set.
enable_security_event_logging: false
syslog_drain_buffer_size: 10000
#syslog_host: syslog.lab13.lab.local.domain
syslog_port: 514
#syslog_protocol: udp


# Deployment
deployment_network_name: "DEPLOYMENT"
deployment_vsphere_network: pcf2_deployment   # vCenter Deployment network name
deployment_nw_cidr: 10.13.22.0/24           # Deployment network CIDR, ex: 10.0.0.0/22
deployment_excluded_range: 10.13.22.1-10.13.22.10    # Deployment network exclusion range
deployment_nw_dns: 192.13.1.10            # Deployment network DNS
deployment_nw_gateway: 10.13.22.1        # Deployment network Gateway
deployment_nw_azs: AZ1,AZ2,AZ3            # Comma separated list of AZ's to be associated with this network

## Domain names for deployment
apps_domain: apps.pcf2.lab13.lab.local.domain   # e.g. apps.pcf.example.com
system_domain: system.pcf2.lab13.lab.local.domain # e.g. system.pcf.example.com

# Disable HTTP on gorouters (true|false)
disable_http_proxy: false

# If true, disable insecure cookies on the router.
disable_insecure_cookies: false

# Dynamic Services Network
dynamic_services_network_name: "DYNAMIC-SERVICES"
dynamic_services_vsphere_network: pcf2_dynsvcs     # vCenter Dynamic Services network name
dynamic_services_nw_cidr: 10.13.24.0/24             # Dynamic Services network CIDR, ex: 10.0.0.0/22
dynamic_services_excluded_range: 10.13.24.1-10.13.24.10     # Dynamic Services network exclusion range
dynamic_services_nw_dns: 192.13.1.10              # Dynamic Services network DNS
dynamic_services_nw_gateway: 10.13.24.1          # Dynamic Services network Gateway
dynamic_services_nw_azs: AZ1,AZ2,AZ3              # Comma separated list of AZ's to be associated with this network

# Whether to enable BOSH VM resurrector
enable_vm_resurrector: true

# Errands to disable prior to deploying ERT
# Valid values:
#   all
#   none
#   "" (empty string - equivalent to none)
#   Any combination of the following, separated by comma:
#     smoke-tests
#     push-apps-manager
#     notifications
#     notifications-ui
#     push-pivotal-account
#     autoscaling
#     autoscaling-register-broker
#     nfsbrokerpush
ert_errands_to_disable:     # Comma-separated list of errand names to disable before deploy
ert_errands_to_run_on_change: all

# PCF Elastic Runtime minor version to track
ert_major_minor_version: 2\.[0-9\]+\.[0-9]+$

# AZ to use for deployment of ERT Singleton jobs
ert_singleton_job_az: AZ1

# Applications Network Maximum Transmission Unit bytes
garden_network_mtu: 1454

# Only change this if you need to avoid address collision with a third-party service on the same subnet.
garden_network_pool_cidr: 10.254.0.0/22

# Optional - if your git repo requires an SSH key.
git_private_key:

# Required if haproxy_forward_tls is enabled - HAProxy will use the CA provided to verify the certificates provided by the router.
haproxy_backend_ca:

# If enabled HAProxy will forward all requests to the router over TLS (enable|disable)
haproxy_forward_tls: false

# Network configuration for Ops Director
icmp_checks_enabled: false    # Enable or disable ICMP checks

# Whether to disable SSL cert verification for this environment
ignore_ssl_cert_verification: true

# Infrastructure Configuration
infra_network_name: "INFRASTRUCTURE"
infra_vsphere_network: pcf2_infra        # vCenter Infrastructure network name
infra_nw_cidr: 10.13.21.0/24                # Infrastructure network CIDR, ex: 10.0.0.0/22
infra_excluded_range: 10.13.21.1-10.13.21.10         # Infrastructure network exclusion range
infra_nw_dns: 192.13.1.10                 # Infrastructure network DNS
infra_nw_gateway: 10.13.21.1             # Infrastructure network Gateway
infra_nw_azs: AZ1,AZ2,AZ3                 # Comma separated list of AZ's to be associated with this network

# IPs
ha_proxy_ips:           # Comma-separated list of static IPs
router_static_ips: 10.13.22.11,10.13.22.12,10.13.22.13     # Comma-separated list of static IPs
tcp_router_static_ips: 10.13.22.20,10.13.22.21,10.13.22.22,10.13.22.23,10.13.22.24,10.13.22.25 # Comma-separated list of static IPs
ssh_static_ips:         # Comma-separated list of static IPs
mysql_static_ips: 10.13.22.17,10.13.22.18,10.13.22.19      # Comma-separated list of static IPs


# Instances
## Default resource configuration
## these resources can take any parameter made available in
## the ops manager API ( https://<your-ops-man/docs#configuring-resources-for-a-job )
backup_prepare_instances: 0 #default 0
clock_global_instances: 1 #default 1
cloud_controller_instances: 2 #default 2
cloud_controller_worker_instances: 2 #default 2
consul_server_instances: 3 #default 3
credhub_instances: 0 #default 0
diego_brain_instances: 3 #default 3
diego_cell_instances: 3 # minimum 3
diego_database_instances: 3 #default 3
doppler_instances: 3 #default 3
ha_proxy_instances: 0 #default 0
loggregator_trafficcontroller_instances: 3 #default 3
mysql_instances: 3 #default 3
mysql_monitor_instances: 1 #default 1
mysql_proxy_instances: 2 #default 2
nats_instances: 2 #default 2
nfs_server_instances: 1 #default 1
router_instances: 3 #default 3
syslog_adapter_instances: 3 #default 3
syslog_scheduler_instances: 2 #default 2
tcp_router_instances: 0 #default 0
uaa_instances: 2 #default 2

# Whether or not the ERT VMs are internet connected.
internet_connected: true

# Loggegrator Port. Default is 443
loggregator_endpoint_port:

# Max threads count for deploying VMs
max_threads: 32

# Whether to enable MySQL backups. (disable|s3|scp)
mysql_backups: disable

# Email address to receive MySQL monitor notifications
mysql_monitor_email: mysql@lab13.lab.local.domain

# S3 backup config params (leave empty values if you’re not using s3)
mysql_backups_s3_access_key_id:
mysql_backups_s3_bucket_name:
mysql_backups_s3_bucket_path:
mysql_backups_s3_cron_schedule:
mysql_backups_s3_endpoint_url:
mysql_backups_s3_secret_access_key:

# SCP backup config params (leave empty values if you’re not using scp)
mysql_backups_scp_cron_schedule:
mysql_backups_scp_destination:
mysql_backups_scp_key:
mysql_backups_scp_port:
mysql_backups_scp_server:
mysql_backups_scp_user:

#nsx configuration
nsx_networking_enabled: true # (true|false) to use nsx networking feature
nsx_mode: nsx-t
nsx_address:  lab13-nsxm.lab13.lab.local.domain
nsx_username: admin
nsx_password: YOURPASSWORD
nsx_ca_certificate: |
 -----BEGIN CERTIFICATE-----
 ...
 -----END CERTIFICATE-----
# NSX-T Related portion
nsx_subnet_prefix: 24                    # default 24 - 256 addresses in a given org
nsx_log_dropped_traffic: false           # default false
nsx_enable_snat: true                    # earlier used to be "enable" or "disable"
nsx_external_subnet_prefix: 24           # Check value from NSX-T
nsx_foundation_name: "PCF2"            # value of "ncp/cluster" tag in Tier0 Router
nsx_ncp_debug_log: false                 # Default false, boolean type
nsx_product_tile_name: "VMware-NSX-T"  # fixed for NSX-T CNI Add-on tile
nsx_auth_type: simple                # can be "simple" or "client_cert", simple would used previously configured nsx-t creds
nsx_client_cert_cert:
nsx_client_cert_private_key:
overlay_tz: "tz-overlay"  #name or UUID of existing overlay Transport Zone in NSX-T
tier0_router: "tier0-activepassive" #name or UUID of existing Tier0 router to connect to 
container_ip_blocks_name: "ip-block-pks-deployments" #name or UUID of existing IP Block 
external_ip_pools_name: "ip-pool-vips" #name of UUID of existing IP Pools or external IPS for NAT

 # nsx fields
# leave nsx fields empty if you are not leveraging the nsx features for a given component
diego_brain_nsx_lb_edge_name:
diego_brain_nsx_lb_pool_name:
diego_brain_nsx_lb_port:
diego_brain_nsx_lb_security_group:
diego_brain_nsx_security_group:
mysql_nsx_lb_edge_name:
mysql_nsx_lb_pool_name:
mysql_nsx_lb_port:
mysql_nsx_lb_security_group: pcf2-lb-mysql
mysql_nsx_security_group: pcf2-mysql
router_nsx_lb_edge_name:
router_nsx_lb_pool_name:
router_nsx_lb_port:
router_nsx_lb_security_group: pcf2-lb-routers
router_nsx_security_group: pcf2-routers
tcp_router_nsx_lb_edge_name:
tcp_router_nsx_lb_pool_name:
tcp_router_nsx_lb_port:
tcp_router_nsx_lb_security_group:
tcp_router_nsx_security_group:

# Comma-separated list of NTP servers to use for VMs deployed by BOSH
ntp_servers: minnie.lss.emc.com

# Decryption password for Ops Manager exported settings
om_decryption_pwd: YOURPASSWORD

# Comma separated list of DNS servers used by Ops Manager
om_dns_servers: 192.13.1.10

# Gateway for Ops Manager network
om_gateway: 10.13.21.1

# IP to assign to Ops Manager VM
om_ip: 10.13.21.10

# Netmask for Ops Manager network
om_netmask: 255.255.255.0

# Comma-separated list of NTP Servers
om_ntp_servers: ntp.local.domain

# vCenter Cluster or Resource Pool to use to deploy Ops Manager.
# Possible formats:
#   cluster:       /<Data Center Name>/host/<Cluster Name>
#   resource pool: /<Data Center Name>/host/<Cluster Name>/Resources/<Resource Pool Name>
om_resource_pool: /VxRail-Lab13/host/AZ1/Resources/PCF2

# Optional - vCenter folder to put Ops Manager in
om_vm_folder: PCF2

# Optional - vCenter host to deploy Ops Manager in
om_vm_host:

# Name to use for Ops Manager VM
om_vm_name: opsman-pcf2

# vCenter network name to use to deploy Ops Manager in
om_vm_network: pcf2_infra

# Whether to power on Ops Manager VM after creation
om_vm_power_state: true

# Optional DNS name for Ops Director. Should be reachable from all networks.
ops_dir_hostname:

# opsman_admin_username/opsman_admin_password needs to be specified
opsman_admin_username: admin       # Username for Ops Manager admin account
opsman_admin_password: YOURPASSWORD       # Password for Ops Manager admin account

# Disk type for Ops Manager VM (thick|thin)
opsman_disk_type: "thin"

# FQDN to access Ops Manager without protocol (will use https), ex: opsmgr.example.com
opsman_domain_or_ip_address: opsmgr.pcf2.lab13.lab.local.domain


# SSH password for Ops Manager (ssh user is ubuntu)
opsman_ssh_password: YOURPASSWORD

# Pivnet token for downloading resources from Pivnet. Find this token at https://network.pivotal.io/users/dashboard/edit-profile
#pivnet_token: CHANGEME

# Optional. If blank the cert(s) will be generated
ssl_cert: |
 -----BEGIN CERTIFICATE-----
 ...
 -----END CERTIFICATE-----
 -----BEGIN CERTIFICATE-----
 ...
 -----END CERTIFICATE-----
 -----BEGIN CERTIFICATE-----
 ...
 -----END CERTIFICATE-----
ssl_private_key: |
 -----BEGIN PRIVATE KEY-----
 ...
 -----END PRIVATE KEY-----


# Request timeout for gorouter
router_request_timeout_in_seconds: 900

# Enable/disable route services (enable|disable)
route_services: disable

# Optional - these certificates can be used to validate the certificates from incoming client requests.
# All CA certificates should be appended together into a single collection of PEM-encoded entries.
routing_custom_ca_certificates:

# Support for the X-Forwarded-Client-Cert header. Possible values: (load_balancer|ha_proxy|router)
routing_tls_termination: router

## Wildcard domain certs go here
# Optional. Will be generated if blank.
saml_ssl_cert: |
 -----BEGIN CERTIFICATE-----
 ...
 -----END CERTIFICATE-----
 -----BEGIN CERTIFICATE-----
 ...
 -----END CERTIFICATE-----
 -----BEGIN CERTIFICATE-----
 ...
 -----END CERTIFICATE-----
saml_ssl_private_key: |
 -----BEGIN PRIVATE KEY-----
 ...
 -----END PRIVATE KEY-----
# Setting appropriate Application Security Groups is critical for a secure
# deployment. Change the value of the param below to "X" to acknowledge that
# once the Elastic Runtime deployment completes, you will review and set the
# appropriate application security groups.
# See https://docs.pivotal.io/pivotalcf/opsguide/app-sec-groups.html
security_acknowledgement: X

# Services network
services_network_name: "SERVICES"
services_vsphere_network: pcf2_services     # vCenter Services network name
services_nw_cidr: 10.13.23.0/24             # Services network CIDR, ex: 10.0.0.0/22
services_excluded_range: 10.13.23.1-10.13.23.10      # Services network exclusion range
services_nw_dns: 192.13.1.10              # Services network DNS
services_nw_gateway: 10.13.23.1          # Services network Gateway
services_nw_azs: AZ1,AZ2,AZ3              # Comma separated list of AZ's to be associated with this network


# If true, disable SSL certificate verification for this environment.
skip_cert_verify: true

# If smtp_address is configured, smtp_from, smtp_port, smtp_user, smtp_pwd,
# smtp_enable_starttls_auto, and smtp_auth_mechanism must also be set.
smtp_address:
smtp_auth_mechanism: # (none|plain|cram-md5)
smtp_enable_starttls_auto: true
smtp_from:
smtp_port:
smtp_pwd:
smtp_user:

# Storage
ephemeral_storage_names: VxRail-Virtual-SAN-Datastore-375c9559-4624-4ffc-adf4-8cbb3aa7d29e,VxRail-Virtual-SAN-Datastore-ba9b985e-a3d3-486f-87d6-326f3f219159,VxRail-Virtual-SAN-Datastore-91eb78a0-165a-4249-9c40-3d3c14072dcf  # Ephemeral Storage names in vCenter for use by PCF
persistent_storage_names: VxRail-Virtual-SAN-Datastore-375c9559-4624-4ffc-adf4-8cbb3aa7d29e,VxRail-Virtual-SAN-Datastore-ba9b985e-a3d3-486f-87d6-326f3f219159,VxRail-Virtual-SAN-Datastore-91eb78a0-165a-4249-9c40-3d3c14072dcf # Persistent Storage names in vCenter for use by PCF


# Enable/disable TCP routing (enable|disable)
tcp_routing: disable

# A comma-separated list of ports and hyphen-separated port ranges, e.g. 52135,34000-35000,23478
tcp_routing_ports:

# Optional PEM-encoded certificates to add to BOSH director
trusted_certificates: |
 -----BEGIN CERTIFICATE-----
 ...
 -----END CERTIFICATE-----

# vCenter configuration
vcenter_ca_cert: CHANGEME          # vCenter CA cert at the API endpoint; enter a value if `vcenter_insecure: 0`
vcenter_host: lab13-vcsa-wkld.lab13.lab.local.domain       # vCenter host or IP
vcenter_usr: administrator@vsphere.local              # vCenter username. If user is tied to a domain, then escape the \, example `domain\\user`
vcenter_pwd: YOURPASSWORD              # vCenter password
vcenter_datacenter: VxRail-Lab13       # vCenter datacenter
vcenter_insecure: 1         # vCenter skip TLS cert validation; enter `1` to disable cert verification, `0` to enable verification
vcenter_datastore: VxRail-Virtual-SAN-Datastore-375c9559-4624-4ffc-adf4-8cbb3aa7d29e           # vCenter datastore name to deploy Ops Manager in

# Disk type for BOSH provisioned VM. (thick|thin)
vm_disk_type: "thin"

# offline resource config
s3_endpoint: https://minio.lab13.lab.local.domain:9000
s3_bucket: binaries 
s3_access_key_id: MYACCESSKEY
s3_secret_access_key: MYSECRETKEY